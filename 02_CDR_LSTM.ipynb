{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da065482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---This program is used to forecast 1 week CDRs based on 55 previous days' data\n",
    "\n",
    "#---Install these bibs so the program works properly\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d10ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Loading Cell_ID vector, whose elements tell from which ID the matrix_TS row is the corresponding time-series\n",
    "\n",
    "Cell_ID = loadtxt('ID_labels.csv', delimiter=',') \n",
    "df = pd.read_csv('matrixTS.csv',header=None)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ce0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Defines the Cell ID to be forecasted and plots the corresponding time-series\n",
    "\n",
    "days = 62 #Train and validation size need to be changed if this value is tunned\n",
    "matrix = df.to_numpy()\n",
    "\n",
    "ID=60\n",
    "time_series = matrix[ID][:]\n",
    "hour = np.linspace(0,24*days,24*days)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title('Traffic load of Cell ID = %d' % (Cell_ID[60])) \n",
    "plt.plot(hour,time_series,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca275d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---This function creates the sliding window to construct the training data set\n",
    "\n",
    "def df_to_X_y(df,window_size):\n",
    "    df_as_np = df\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np)-window_size):\n",
    "        row = [[a] for a in df_as_np[i:i+window_size]] \n",
    "        X.append(row)\n",
    "        y.append(df_as_np[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#-Each vector of matrix X contains \"window_size\" elements used as input to train the model\n",
    "#-Each element of vector y contains one element that the model needs to predict based on the respective row of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Standardization of the CDR time-series\n",
    "\n",
    "train_size = 24*50 # defines number of samples of training data: 50 days with 24 samples each\n",
    "validation_size = 24*5 # defines number of samples of validation data: 5 days with 24 samples each\n",
    "\n",
    "time_series_mean = time_series[:train_size].mean() #--Considering just the training part\n",
    "time_series_std = time_series[:train_size].std() #--Considering just the training part\n",
    "\n",
    "time_series_standardized = (time_series - time_series_mean) / time_series_std\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title('Traffic load of Cell ID = %d standardized' % (Cell_ID[60])) \n",
    "plt.plot(hour,time_series_standardized,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 24\n",
    "X,y = df_to_X_y(time_series_standardized,WINDOW_SIZE)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252f57e",
   "metadata": {},
   "source": [
    "## Splitting data to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ae6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:(train_size+validation_size)], y[train_size:(train_size+validation_size)]\n",
    "y_test = time_series[(train_size+validation_size):]\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce7293",
   "metadata": {},
   "source": [
    "## Constructing LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(InputLayer((WINDOW_SIZE,1)))\n",
    "\n",
    "#-Comment or uncomment lines to insert/remove layers of the LSTM\n",
    "#-Change the number of neurons inside each layers\n",
    "\n",
    "#model1.add(LSTM(128,return_sequences=True)) # default activation function is tanh\n",
    "#model1.add(LSTM(128,return_sequences=True)) # default activation function is tanh\n",
    "model1.add(LSTM(64,return_sequences=True)) # default activation function is tanh\n",
    "model1.add(LSTM(64)) # default activation function is tanh\n",
    "\n",
    "model1.add(Dense(32,'relu'))\n",
    "model1.add(Dense(1,'linear'))\n",
    "\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e18848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--Model Training\n",
    "\n",
    "#-Set the hyperparemeters according to your application: learning_rate, epochs, batch size\n",
    "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])\n",
    "model1.fit(X_train,y_train, validation_data=(X_val,y_val),epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Predictions for \"N_day_pred\" days\n",
    "\n",
    "predictions_standardized = []\n",
    "vec_last_samples = X_val[len(y_val)-1]\n",
    "\n",
    "vec_last_samples = vec_last_samples.reshape((vec_last_samples.shape[1], vec_last_samples.shape[0], 1))\n",
    "\n",
    "N_day_pred = 7\n",
    "for i in range(0,24*N_day_pred):\n",
    "    prediction = model1.predict(vec_last_samples).flatten() #flatten() is just to take the []\n",
    "    predictions_standardized.append(prediction)\n",
    "    \n",
    "    for j in range(0,WINDOW_SIZE-1):\n",
    "        vec_last_samples[0,j,0] = vec_last_samples[0,j+1,0]\n",
    "    vec_last_samples[0,int(WINDOW_SIZE-1),0] = prediction\n",
    "    #print(vec_last_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Plotting the predictions\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title('Prediction for Cell ID = %d (standardized)' % (Cell_ID[60])) \n",
    "plt.plot(predictions_standardized,'r')\n",
    "plt.plot(time_series_standardized[train_size+validation_size:],'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ef13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Ploting the actual result (not considering mean and std)\n",
    "predictions_standardized = np.array(predictions_standardized)\n",
    "predictions_week = predictions_standardized*time_series_std+time_series_mean\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title('Prediction for Cell ID = %d' % (Cell_ID[60])) \n",
    "plt.plot(predictions_week,'r')\n",
    "plt.plot(y_test,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3069e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(predictions_week,y_test)\n",
    "MSE = mean_squared_error(predictions_week,y_test)\n",
    "print('MAE:', \"%.3f\" % MAE)\n",
    "print('MSE:', \"%.3f\" % MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f832a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1deff45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c53f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27123ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58896e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515a504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c6d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec66c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b896c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
